{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "859d38e7-11c0-48bc-978a-d0e907f19ed1",
   "metadata": {
    "id": "859d38e7-11c0-48bc-978a-d0e907f19ed1"
   },
   "source": [
    "# 7 WorkFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c586e3-ed7d-44b2-92a0-f19669f06940",
   "metadata": {
    "id": "29c586e3-ed7d-44b2-92a0-f19669f06940"
   },
   "source": [
    "### 7.1 Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff8327-10ed-4b11-bbee-f1c3f357d123",
   "metadata": {
    "id": "6fff8327-10ed-4b11-bbee-f1c3f357d123"
   },
   "source": [
    "Presentar un workflow/pipeline completo al que los estudiantes deberán enriquecer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PX0qg_c0yqob",
   "metadata": {
    "id": "PX0qg_c0yqob"
   },
   "source": [
    "#### 7.2  Seteo del ambiente en Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NGY7H9xza7Zr",
   "metadata": {
    "id": "NGY7H9xza7Zr"
   },
   "source": [
    "Esta parte se debe correr con el runtime en Python3\n",
    "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7PupIBNba7Zr",
   "metadata": {
    "id": "7PupIBNba7Zr"
   },
   "source": [
    "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9LpZCst5a7Zs",
   "metadata": {
    "id": "9LpZCst5a7Zs"
   },
   "outputs": [],
   "source": [
    "# primero establecer el Runtime de Python 3\n",
    "from google.colab import drive\n",
    "drive.mount('/content/.drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JYC_F-wla7Zs",
   "metadata": {
    "id": "JYC_F-wla7Zs"
   },
   "source": [
    "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
    "\n",
    "<br>los siguientes comando estan en shell script de Linux\n",
    "*   Crear las carpetas en el Google Drive\n",
    "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
    "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
    "*   Bajar el **dataset_historico** al Google Drive y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcqHsG9hdlx",
   "metadata": {
    "id": "4fcqHsG9hdlx"
   },
   "source": [
    "*  Si usted eligió modalidad *Gerencial* entonces NO debe modificar nada, su liderazgo logró que otras trabajaron por usted\n",
    "*  Si usted eligió modalidad de *Analista Junior*, entonces donde dice archivo=\"gerencial_competencia_2025.csv.gz\"  lo debe cambiar por  archivo=\"analistajr_competencia_2025.csv.gz\"\n",
    "*  Si usted eligió modalidad *Analista Senior*,  ya se las ingenierá SIN preguntar !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XWLelftXa7Zt",
   "metadata": {
    "id": "XWLelftXa7Zt"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "\n",
    "mkdir -p \"/content/.drive/My Drive/labo1\"\n",
    "mkdir -p \"/content/buckets\"\n",
    "ln -s \"/content/.drive/My Drive/labo1\" /content/buckets/b1\n",
    "\n",
    "mkdir -p ~/.kaggle\n",
    "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
    "chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "\n",
    "mkdir -p /content/buckets/b1/exp\n",
    "mkdir -p /content/buckets/b1/datasets\n",
    "mkdir -p /content/datasets\n",
    "\n",
    "\n",
    "webfiles=\"https://storage.googleapis.com/open-courses/austral2025-af91/labo1r\"\n",
    "destino_local=\"/content/datasets\"\n",
    "destino_bucket=\"/content/buckets/b1/datasets\"\n",
    "\n",
    "\n",
    "archivo=\"dataset_pequeno.csv\"\n",
    "\n",
    "if ! test -f $destino_bucket/$archivo; then\n",
    "  wget  $webfiles/$archivo  -O $destino_bucket/$archivo\n",
    "fi\n",
    "\n",
    "\n",
    "if ! test -f $destino_local/$pequeno; then\n",
    "  cp  $destino_bucket/$archivo  $destino_local/$archivo\n",
    "fi\n",
    "\n",
    "#-------\n",
    "\n",
    "archivo=\"gerencial_competencia_2025.csv.gz\"\n",
    "\n",
    "if ! test -f $destino_bucket/$archivo; then\n",
    "  wget  $webfiles/$archivo  -O $destino_bucket/$archivo\n",
    "fi\n",
    "\n",
    "\n",
    "if ! test -f $destino_local/$pequeno; then\n",
    "  cp  $destino_bucket/$archivo  $destino_local/$archivo\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oSKhZRToy2F7",
   "metadata": {
    "id": "oSKhZRToy2F7"
   },
   "source": [
    "## 7.3  Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85171302-a2d6-48cb-b9b2-8d839a276859",
   "metadata": {
    "id": "85171302-a2d6-48cb-b9b2-8d839a276859"
   },
   "source": [
    "## Inicializacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eSU5vi00CPRS",
   "metadata": {
    "id": "eSU5vi00CPRS"
   },
   "source": [
    "Esta parte se debe correr con el runtime en lenguaje **R** Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Zq8dySimCPRT",
   "metadata": {
    "id": "Zq8dySimCPRT"
   },
   "source": [
    "limpio el ambiente de R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "EL8wdHaUs59K",
   "metadata": {
    "id": "EL8wdHaUs59K"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Sat Jun 07 12:38:02 2025'"
      ],
      "text/latex": [
       "'Sat Jun 07 12:38:02 2025'"
      ],
      "text/markdown": [
       "'Sat Jun 07 12:38:02 2025'"
      ],
      "text/plain": [
       "[1] \"Sat Jun 07 12:38:02 2025\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1iE0U4_WCPRT",
   "metadata": {
    "id": "1iE0U4_WCPRT"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 653516</td><td>35.0</td><td>1439454</td><td>76.9</td><td>1439454</td><td>76.9</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>1218173</td><td> 9.3</td><td>8388608</td><td>64.0</td><td>1924971</td><td>14.7</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  653516 & 35.0 & 1439454 & 76.9 & 1439454 & 76.9\\\\\n",
       "\tVcells & 1218173 &  9.3 & 8388608 & 64.0 & 1924971 & 14.7\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |  653516 | 35.0 | 1439454 | 76.9 | 1439454 | 76.9 |\n",
       "| Vcells | 1218173 |  9.3 | 8388608 | 64.0 | 1924971 | 14.7 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
       "Ncells  653516 35.0 1439454    76.9 1439454  76.9\n",
       "Vcells 1218173  9.3 8388608    64.0 1924971  14.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# limpio la memoria\n",
    "rm(list=ls(all.names=TRUE)) # remove all objects\n",
    "gc(full=TRUE, verbose=FALSE) # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "atmIUEUNUrK5",
   "metadata": {
    "id": "atmIUEUNUrK5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: data.table\n",
      "\n",
      "Loading required package: R.utils\n",
      "\n",
      "Loading required package: R.oo\n",
      "\n",
      "Loading required package: R.methodsS3\n",
      "\n",
      "R.methodsS3 v1.8.2 (2022-06-13 22:00:14 UTC) successfully loaded. See ?R.methodsS3 for help.\n",
      "\n",
      "R.oo v1.27.1 (2025-05-02 21:00:05 UTC) successfully loaded. See ?R.oo for help.\n",
      "\n",
      "\n",
      "Attaching package: ‘R.oo’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:R.methodsS3’:\n",
      "\n",
      "    throw\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:methods’:\n",
      "\n",
      "    getClasses, getMethods\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    attach, detach, load, save\n",
      "\n",
      "\n",
      "R.utils v2.13.0 (2025-02-24 21:20:02 UTC) successfully loaded. See ?R.utils for help.\n",
      "\n",
      "\n",
      "Attaching package: ‘R.utils’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:utils’:\n",
      "\n",
      "    timestamp\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    cat, commandArgs, getOption, isOpen, nullfile, parse, use, warnings\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "require(\"data.table\")\n",
    "\n",
    "if( !require(\"R.utils\")) install.packages(\"R.utils\")\n",
    "require(\"R.utils\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BsxZ_ONyj9L_",
   "metadata": {
    "id": "BsxZ_ONyj9L_"
   },
   "source": [
    "#### Parametros\n",
    "Si es gerente, no cambie nada\n",
    "<br>Si es Analista, cambie el nombre del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "peRH7ySLCPRV",
   "metadata": {
    "id": "peRH7ySLCPRV"
   },
   "outputs": [],
   "source": [
    "PARAM <- list()\n",
    "PARAM$semilla_primigenia <- 847117\n",
    "\n",
    "PARAM$experimento <- 7300\n",
    "PARAM$dataset <- \"analistasr_competencia_2025.csv.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NoJbKo_4NG8A",
   "metadata": {
    "id": "NoJbKo_4NG8A"
   },
   "source": [
    "#### Carpeta del Experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1gZD6ZMvCPRV",
   "metadata": {
    "id": "1gZD6ZMvCPRV"
   },
   "outputs": [],
   "source": [
    "# carpeta de trabajo\n",
    "\n",
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento_folder <- paste0(\"WF\", PARAM$experimento)\n",
    "dir.create(experimento_folder, showWarnings=FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YVKBfLtkR8SO",
   "metadata": {
    "id": "YVKBfLtkR8SO"
   },
   "source": [
    "### 7.3.1   Preprocesamiento del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cr3K0RPVRjq6",
   "metadata": {
    "id": "cr3K0RPVRjq6"
   },
   "source": [
    "#### 7.3.1.1  DT incorporar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "Xi0emX2ECPRV",
   "metadata": {
    "id": "Xi0emX2ECPRV"
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in fread(paste0(\"/content/datasets/\", PARAM$dataset)): File '/content/datasets/gerencial_competencia_2025.csv.gz' does not exist or is non-readable. getwd()=='/home/nataliadcdjmarin/buckets/b1/exp/WF7300'\n",
     "output_type": "error",
     "traceback": [
      "Error in fread(paste0(\"/content/datasets/\", PARAM$dataset)): File '/content/datasets/gerencial_competencia_2025.csv.gz' does not exist or is non-readable. getwd()=='/home/nataliadcdjmarin/buckets/b1/exp/WF7300'\nTraceback:\n",
      "1. stopf(\"File '%s' does not exist or is non-readable. getwd()=='%s'\", \n .     file, getwd())",
      "2. raise_condition(stop, gettextf(fmt, ..., domain = domain), c(class, \n .     \"simpleError\", \"error\", \"condition\"))",
      "3. signal(obj)"
     ]
    }
   ],
   "source": [
    "# lectura del dataset\n",
    "dataset <- fread(paste0(\"/content/datasets/\", PARAM$dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MWuPzK3nSLY3",
   "metadata": {
    "id": "MWuPzK3nSLY3"
   },
   "source": [
    "#### 7.3.1.2  CA  Catastrophe Analysis\n",
    "Se intentan reparar las variables que para un mes están con todos los valores en cero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UAI16-yCVcBS",
   "metadata": {
    "id": "UAI16-yCVcBS"
   },
   "source": [
    "El método que se utiliza es **Machine Learning** se asigna NA also valores, si ha leido bien, es la \"anti imputación de valores faltantes\"\n",
    "<br> Usted podrá aplicar aquí otros métodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sTmliO_FXv9E",
   "metadata": {
    "id": "sTmliO_FXv9E"
   },
   "outputs": [],
   "source": [
    "dataset[ foto_mes==202006, internet:=NA]\n",
    "dataset[ foto_mes==202006, mrentabilidad:=NA]\n",
    "dataset[ foto_mes==202006, mrentabilidad_annual:=NA]\n",
    "dataset[ foto_mes==202006, mcomisiones:=NA]\n",
    "dataset[ foto_mes==202006, mactivos_margen:=NA]\n",
    "dataset[ foto_mes==202006, mpasivos_margen:=NA]\n",
    "dataset[ foto_mes==202006, mcuentas_saldo:=NA]\n",
    "dataset[ foto_mes==202006, ctarjeta_visa_transacciones:=NA]\n",
    "dataset[ foto_mes==202006, mtarjeta_visa_consumo:=NA]\n",
    "dataset[ foto_mes==202006, mtarjeta_master_consumo:=NA]\n",
    "dataset[ foto_mes==202006, ccallcenter_transacciones:=NA]\n",
    "dataset[ foto_mes==202006, chomebanking_transacciones:=NA]\n",
    "dataset[ foto_mes==202006, chomebanking_transacciones:=NA]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-4NiANYFSYHG",
   "metadata": {
    "id": "-4NiANYFSYHG"
   },
   "source": [
    "#### 7.3.1.3  DR  Data Drifting\n",
    "Se intenta corregir el data drifting, quizas ajustando por IPC ...\n",
    "<br>Esta parte podrá ser abordada por todos los Analistas y también la Gerenciapero se decide pedagogicamente no incluirla en esta primer version para reducir la carga cognitiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L85A2lwKSe3k",
   "metadata": {
    "id": "L85A2lwKSe3k"
   },
   "outputs": [],
   "source": [
    "# sin codigo en esta primera version del workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7sppIDYeSn5X",
   "metadata": {
    "id": "7sppIDYeSn5X"
   },
   "source": [
    "#### 7.3.1.3  FE_intra_manual Feature Engineering intra-mes\n",
    "\n",
    "Agrego campos nuevos dentro del mismo mes, SIN considerar la historia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qrqf3j3_St3p",
   "metadata": {
    "id": "qrqf3j3_St3p"
   },
   "outputs": [],
   "source": [
    "# esta funcion atributos presentes existe debido a que las modalidades poseen datasets con distinta cantidad de campos\n",
    "atributos_presentes <- function( patributos )\n",
    "{\n",
    "  atributos <- unique( patributos )\n",
    "  comun <- intersect( atributos, colnames(dataset) )\n",
    "\n",
    "  return(  length( atributos ) == length( comun ) )\n",
    "}\n",
    "\n",
    "# el mes 1,2, ..12\n",
    "if( atributos_presentes( c(\"foto_mes\") ))\n",
    "  dataset[, kmes := foto_mes %% 100]\n",
    "\n",
    "# variable extraida de una tesis de maestria de Irlanda\n",
    "if( atributos_presentes( c(\"mpayroll\", \"cliente_edad\") ))\n",
    "  dataset[, mpayroll_sobre_edad := mpayroll / cliente_edad]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iC4viwOdY5Kp",
   "metadata": {
    "id": "iC4viwOdY5Kp"
   },
   "outputs": [],
   "source": [
    "# visualizo las columas del dataset a esta etapa\n",
    "colnames(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9682b4ca-3ab3-4bbc-a36a-b185361e6b6b",
   "metadata": {
    "id": "9682b4ca-3ab3-4bbc-a36a-b185361e6b6b"
   },
   "source": [
    "#### 7.3.1.4  FE_rf Feature Engineering de nuevas variables a partir de hojas de Random Forest\n",
    "\n",
    "Esto se mostrará unicamente a la *modalidad Analista Sr*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ljA3h0jOcciP",
   "metadata": {
    "id": "ljA3h0jOcciP"
   },
   "outputs": [],
   "source": [
    "# No se implementa Feature Engineering a partir de Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XaRBjQj8ZRUZ",
   "metadata": {
    "id": "XaRBjQj8ZRUZ"
   },
   "source": [
    "#### 7.3.1.5  FEhist Feature Engineering historico\n",
    "\n",
    "El Fature Engineering Histórico es la etapa que más aporta a la ganancia final, ya que enriquece cada registro del dataset con su historia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe3b8cf-0707-4512-92e7-c1407bb3f73b",
   "metadata": {
    "id": "cfe3b8cf-0707-4512-92e7-c1407bb3f73b"
   },
   "source": [
    "Para cada campo del dataset original (*)\n",
    "se crean lo siguientes campos de a partir de la historia\n",
    "* lag1  lags de orden 1\n",
    "* delta1  =  valor actual - lag1\n",
    "* lag2  lags de orden 2\n",
    "* delta2  = valor actual - lag2\n",
    "\n",
    "\n",
    "(*) Excepto para los campos  <numero_de_cliente,  foto_mes,  clase_ternaria>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7850b948-827d-4a2a-b4d3-a5e459b47c11",
   "metadata": {
    "id": "7850b948-827d-4a2a-b4d3-a5e459b47c11"
   },
   "outputs": [],
   "source": [
    "# Feature Engineering Historico\n",
    "\n",
    "# todo es lagueable, menos la primary key y la clase\n",
    "cols_lagueables <- copy( setdiff(\n",
    "    colnames(dataset),\n",
    "    c(\"numero_de_cliente\", \"foto_mes\", \"clase_ternaria\")\n",
    ") )\n",
    "\n",
    "# https://rdrr.io/cran/data.table/man/shift.html\n",
    "\n",
    "# lags de orden 1\n",
    "dataset[,\n",
    "    paste0(cols_lagueables, \"_lag1\") := shift(.SD, 1, NA, \"lag\"),\n",
    "    by = numero_de_cliente,\n",
    "    .SDcols = cols_lagueables\n",
    "]\n",
    "\n",
    "# lags de orden 2\n",
    "dataset[,\n",
    "    paste0(cols_lagueables, \"_lag2\") := shift(.SD, 2, NA, \"lag\"),\n",
    "    by = numero_de_cliente,\n",
    "    .SDcols = cols_lagueables\n",
    "]\n",
    "\n",
    "# agrego los delta lags\n",
    "for (vcol in cols_lagueables)\n",
    "{\n",
    "    dataset[, paste0(vcol, \"_delta1\") := get(vcol) - get(paste0(vcol, \"_lag1\"))]\n",
    "    dataset[, paste0(vcol, \"_delta2\") := get(vcol) - get(paste0(vcol, \"_lag2\"))]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea690d9-ece9-4852-a5e2-f337c31b6721",
   "metadata": {
    "id": "cea690d9-ece9-4852-a5e2-f337c31b6721"
   },
   "source": [
    "Verificacion de los campos recien creados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f772896b-595a-47d4-8905-c15304ac9452",
   "metadata": {
    "id": "f772896b-595a-47d4-8905-c15304ac9452"
   },
   "outputs": [],
   "source": [
    "ncol(dataset)\n",
    "colnames(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l8mKij0XaDY0",
   "metadata": {
    "id": "l8mKij0XaDY0"
   },
   "source": [
    "#### 7.3.1.6  FEhist Reduccion dimensionalidad con canaritos\n",
    "\n",
    "Esta etapa solo se mostrará a la *modalidad Anlista Sr* por algun canal secreto de forma de no confundir a los *Analista Jr*  nni distraer con detalles operativos a la estratégica *Modalidad Gerencial*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QrmnPtlBcEgx",
   "metadata": {
    "id": "QrmnPtlBcEgx"
   },
   "outputs": [],
   "source": [
    "# No se implementa la reduccion de la dimensionalidad con canaritos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf91ea5e-3341-4afb-8d05-cc4923d3d1e1",
   "metadata": {
    "id": "cf91ea5e-3341-4afb-8d05-cc4923d3d1e1"
   },
   "source": [
    "### 7.3.2 Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526048e4-8cf2-4023-bd2d-a70e4e9ff157",
   "metadata": {
    "id": "526048e4-8cf2-4023-bd2d-a70e4e9ff157"
   },
   "source": [
    "#### 7.3.2.1 Training Strategy\n",
    "\n",
    "Esta etapa de Workflow de  Training Strategy esta pensada para la *Modalidad Gerencial* que posee el dataset de [202005, 202109]\n",
    "<br> Si usted es un Analista, posee el periodo de [201901, 202109] y deberá experimentar en que meses le conviene experimentar\n",
    "\n",
    "<br> A la *Modalidad Gerencial* no se le complicada la vida con el undersampling de los continua, por eso PARAM$trainingstrategy$training_pct <- 1.0\n",
    "<br> Sin embargo, si usted es  *Analista SR* posee un dataset 50 veces ( filas x columnas) más grande que la *Modalidad Gerencial*  y por un tema de velocidad y experimentación más rápida puede llegar a necesitar activar el undersampling de la clase mayoritaria, a pesar de estar corriendo en Google Cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16bc1c1-b3ea-43ca-9d3c-53f8f9ab8ec1",
   "metadata": {
    "id": "f16bc1c1-b3ea-43ca-9d3c-53f8f9ab8ec1"
   },
   "source": [
    "Se hace una estrategia de entrenamiento muy sencilla, tomando todos los meses posibles, SIN eliminar nada x pandemia ni por ningun otro motivo\n",
    "\n",
    "* future = 202109  obviamente completo\n",
    "\n",
    "* final_train =  [ 202005, 202107 ]  con un undersampling de los CONTINUA del 2% por un tema de velocidad\n",
    "\n",
    "* training\n",
    "   * testing = NO HAY\n",
    "   * validation =  202107   completo, sin undersampling\n",
    "   * training = [ 202005, 202106 ]  donde se consideran el 100% de los CONTINUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9c0a42-ba58-4264-8566-091a6161716f",
   "metadata": {
    "id": "2c9c0a42-ba58-4264-8566-091a6161716f"
   },
   "outputs": [],
   "source": [
    "PARAM$trainingstrategy$validate <- c(202107)\n",
    "\n",
    "PARAM$trainingstrategy$training <- c(\n",
    "  202106, 202105, 202104, 202103, 202102, 202101,\n",
    "  202012, 202011, 202010, 202009, 202008, 202007,\n",
    "  202006, 202005\n",
    ")\n",
    "\n",
    "PARAM$trainingstrategy$training_pct <- 1.0\n",
    "\n",
    "\n",
    "PARAM$trainingstrategy$positivos <- c( \"BAJA+1\", \"BAJA+2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tv_trHWAj4a8",
   "metadata": {
    "id": "tv_trHWAj4a8"
   },
   "outputs": [],
   "source": [
    "# seteo la clase01   1={BAJA+1, BAJA+2}   0={CONTINUA}\n",
    "dataset[, clase01 := ifelse( clase_ternaria %in% PARAM$trainingstrategy$positivos, 1, 0 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ud_XDKSIj8f_",
   "metadata": {
    "id": "Ud_XDKSIj8f_"
   },
   "outputs": [],
   "source": [
    "# los campos en los que se entrena\n",
    "campos_buenos <- copy( setdiff(\n",
    "    colnames(dataset), c(\"clase_ternaria\",\"clase01\",\"azar\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rFKgZZPSj_Pa",
   "metadata": {
    "id": "rFKgZZPSj_Pa"
   },
   "outputs": [],
   "source": [
    "# preparo para que se puede hacer undersampling de los CONTINUA\n",
    "#  solamente por un tema de VELOCIDAD\n",
    "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
    "dataset[, azar:=runif(nrow(dataset))]\n",
    "\n",
    "# undersampling de los CONTINUA\n",
    "dataset[, fold_train :=  foto_mes %in%  PARAM$trainingstrategy$training &\n",
    "    (clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\") |\n",
    "     azar < PARAM$trainingstrategy$training_pct ) ]\n",
    "\n",
    "\n",
    "if( !require(\"lightgbm\")) install.packages(\"lightgbm\")\n",
    "require(\"lightgbm\")\n",
    "\n",
    "dtrain <- lgb.Dataset(\n",
    "  data= data.matrix(dataset[fold_train == TRUE, campos_buenos, with = FALSE]),\n",
    "  label= dataset[fold_train == TRUE, clase01],\n",
    "  free_raw_data= TRUE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B3yo98kQkHcP",
   "metadata": {
    "id": "B3yo98kQkHcP"
   },
   "outputs": [],
   "source": [
    "# datos de validation\n",
    "dvalidate <- lgb.Dataset(\n",
    "  data= data.matrix(dataset[foto_mes %in% PARAM$trainingstrategy$validate, campos_buenos, with = FALSE]),\n",
    "  label= dataset[foto_mes %in% PARAM$trainingstrategy$validate, clase01],\n",
    "  free_raw_data= TRUE\n",
    ")\n",
    "\n",
    "nrow(dvalidate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e8f788-551c-4e50-9029-302ac0834287",
   "metadata": {
    "id": "28e8f788-551c-4e50-9029-302ac0834287"
   },
   "source": [
    "####  7.3.2.2. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5fc836-e222-4aeb-a6a8-157346895ef7",
   "metadata": {
    "id": "bf5fc836-e222-4aeb-a6a8-157346895ef7"
   },
   "source": [
    "* Clase binaria que se optimiza :  positivos = [ BAJA+1, BAJA+2 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885c03b5-77bc-4510-a930-0d1f14b52ffb",
   "metadata": {
    "id": "885c03b5-77bc-4510-a930-0d1f14b52ffb"
   },
   "source": [
    "* Metrica que se optimiza **AUC** Area Under Curve de la  ROC Curve\n",
    "\n",
    "es muy importante notar que intencionalmente  **NO** se está optimizando la funcion de ganancia del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e6f95c-66ef-4ab9-9ba3-fcc099816704",
   "metadata": {
    "id": "b7e6f95c-66ef-4ab9-9ba3-fcc099816704"
   },
   "source": [
    "* Cantidad de iteraciones inteligentes de la Optimizacion Bayesiana = **10**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe047a87-e2d0-4418-97dd-0a881e66d73a",
   "metadata": {
    "id": "fe047a87-e2d0-4418-97dd-0a881e66d73a"
   },
   "source": [
    "* Parametros no default, fijos de LightGBM que no se optimizan\n",
    "  * max_bin = 31 , Alienigenas Ancestrales contruyeron las pirámides y dejaron a la humanidad en un jeroglifico  *max_bin=31*\n",
    "  * feature_fraction = 0.5  para poner algo que generalmente no falla\n",
    "  * learning_rate = 0.03  para que aprenda lento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7da08e-fe57-4681-beff-11fe963116bd",
   "metadata": {
    "id": "1e7da08e-fe57-4681-beff-11fe963116bd"
   },
   "source": [
    "* Parametros que se optimizan en la Bayesian Optimization\n",
    "  * num_leaves  [8, 256]\n",
    "  * min_data_in_leaf  [8, 8192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34V6y4GetKq_",
   "metadata": {
    "id": "34V6y4GetKq_"
   },
   "outputs": [],
   "source": [
    "# paquetes necesarios para la Bayesian Optimization\n",
    "if(!require(\"DiceKriging\")) install.packages(\"DiceKriging\")\n",
    "require(\"DiceKriging\")\n",
    "\n",
    "if(!require(\"mlrMBO\")) install.packages(\"mlrMBO\")\n",
    "require(\"mlrMBO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UFbDSYtH0TTT",
   "metadata": {
    "id": "UFbDSYtH0TTT"
   },
   "source": [
    "Definición de la Bayesian Optimization\n",
    "<br> Si se desea optimizar un hiperparámetro que esta como fijo, debe QUITARSE de param_fijos y agregarse a PARAM$hipeparametertuning$hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5Uag3XGHqrfZ",
   "metadata": {
    "id": "5Uag3XGHqrfZ"
   },
   "outputs": [],
   "source": [
    "# valor ridiculamente bajo para que corra rapido en el aula y no molestar a la *Modalidad Gerencial*\n",
    "PARAM$hipeparametertuning$num_interations <- 10\n",
    "\n",
    "# parametros fijos del LightGBM\n",
    "PARAM$lgbm$param_fijos <- list(\n",
    "  objective= \"binary\",\n",
    "  metric= \"auc\",\n",
    "  first_metric_only= TRUE,\n",
    "  boost_from_average= TRUE,\n",
    "  feature_pre_filter= FALSE,\n",
    "  verbosity= -100,\n",
    "  force_row_wise= TRUE, # para evitar warning\n",
    "  seed= PARAM$semilla_primigenia,\n",
    "  max_bin= 31,\n",
    "  learning_rate= 0.03,\n",
    "  feature_fraction= 0.5,\n",
    "  num_iterations= 2048,  # valor grande, lo limita early_stopping_rounds\n",
    "  early_stopping_rounds= 200\n",
    ")\n",
    "\n",
    "PARAM$hipeparametertuning$hs <- makeParamSet(\n",
    "  makeIntegerParam(\"num_leaves\", lower = 2L, upper = 256L),\n",
    "  makeIntegerParam(\"min_data_in_leaf\", lower = 2L, upper = 8192L)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FEa1UuuAz4yj",
   "metadata": {
    "id": "FEa1UuuAz4yj"
   },
   "source": [
    "Función \"señora caja negra\"  que es llamada para verificar la realidad por la Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c10f535-8d90-47d1-ac3d-9b4c24ec21d2",
   "metadata": {
    "id": "2c10f535-8d90-47d1-ac3d-9b4c24ec21d2"
   },
   "outputs": [],
   "source": [
    "# En  x llegan los parmaetros de la bayesiana\n",
    "#  devuelve la AUC en validate del modelo entrenado\n",
    "#  en el parametro x llegan los hiperparámetros que se estan optimizando\n",
    "\n",
    "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
    "\n",
    "  message(format(Sys.time(), \"%a %b %d %X %Y\"))\n",
    "\n",
    "  # uno la lista de hiperparametros : fijos + variables\n",
    "  param_completo <- c(PARAM$lgbm$param_fijos, x)\n",
    "\n",
    "  # entreno LightGBM\n",
    "  modelo_train <- lgb.train(\n",
    "    data= dtrain,\n",
    "    valids= list(valid = dvalidate),\n",
    "    eval= \"auc\",\n",
    "    param= param_completo,\n",
    "    verbose= -100\n",
    "  )\n",
    "\n",
    "  # recupero la AUC en validation\n",
    "  AUC <- modelo_train$record_evals$valid$auc$eval[[modelo_train$best_iter]]\n",
    "\n",
    "  # esta es la forma de devolver un parametro extra\n",
    "  attr(AUC, \"extras\") <- list(\"num_iterations\"= modelo_train$best_iter)\n",
    "\n",
    "  # hago espacio en la memoria\n",
    "  rm(modelo_train)\n",
    "  gc(full= TRUE, verbose= FALSE)\n",
    "\n",
    "  return(AUC)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267a35d4-adaf-4271-a875-3864111333b7",
   "metadata": {
    "id": "267a35d4-adaf-4271-a875-3864111333b7"
   },
   "source": [
    "seteo de la Bayesian Optimization (complejo)\n",
    "<br> copiado y pegado de la documentación de la librería"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c2a92d-1041-46b8-bff2-47297f209ed2",
   "metadata": {
    "id": "43c2a92d-1041-46b8-bff2-47297f209ed2"
   },
   "outputs": [],
   "source": [
    "configureMlr(show.learner.output = FALSE)\n",
    "\n",
    "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "# por favor, no desesperarse por lo complejo\n",
    "obj.fun <- makeSingleObjectiveFunction(\n",
    "    fn= EstimarGanancia_AUC_lightgbm, # la funcion que voy a maximizar\n",
    "    minimize= FALSE, # estoy Maximizando AUC\n",
    "    noisy= FALSE,\n",
    "    par.set= PARAM$hipeparametertuning$hs,\n",
    "    has.simple.signature= FALSE # paso los parametros en una lista\n",
    ")\n",
    "\n",
    "# cada 600 segundos guardo el resultado intermedio\n",
    "ctrl <- makeMBOControl(\n",
    "    save.on.disk.at.time= 600,\n",
    "    save.file.path= \"HT.RDATA\"\n",
    ")\n",
    "\n",
    "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
    "ctrl <- setMBOControlTermination(\n",
    "    ctrl,\n",
    "    iters= PARAM$hipeparametertuning$num_interations  # cantidad de iteraciones inteligentes\n",
    ")\n",
    "\n",
    "# defino el método estandar para la creacion de los puntos iniciales\n",
    "#   los \"No Inteligentes\"\n",
    "ctrl <- setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())\n",
    "\n",
    "# mas configuraciones\n",
    "surr.km <- makeLearner(\n",
    "    \"regr.km\",\n",
    "    predict.type= \"se\",\n",
    "    covtype= \"matern3_2\",\n",
    "    control= list(trace = TRUE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1e5645-d26f-4923-a53f-f30471a4c4e8",
   "metadata": {
    "id": "6c1e5645-d26f-4923-a53f-f30471a4c4e8"
   },
   "source": [
    "Corrida de la Bayesian Optimization,  aqui se hace el trabajo pesado\n",
    "<br> por favor no se asuste con los warnings que pudieran aparecer\n",
    "\n",
    "Si corrío a medias y llegó a las iteraciones inteligentes, en el archivo binario HT.RDATA quedó lo ya procesado y es utilizado para retomar la corrida desde lo último que llegó a grabar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8cab3f-c7e2-4802-bfd1-5ad509922a4e",
   "metadata": {
    "id": "1f8cab3f-c7e2-4802-bfd1-5ad509922a4e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# inicio la optimizacion bayesiana\n",
    "\n",
    "if (!file.exists(\"HT.RDATA\")) {\n",
    "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
    "} else {\n",
    "  bayesiana_salida <- mboContinue(\"HT.RDATA\") # retomo en caso que ya exista\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36307612-964f-4df3-907a-1bc3c095f178",
   "metadata": {
    "id": "36307612-964f-4df3-907a-1bc3c095f178"
   },
   "source": [
    "la bayesian optimization ha corrido, extraigo los mejores hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c061a2a-3341-4006-a154-c95bb6cfd407",
   "metadata": {
    "id": "8c061a2a-3341-4006-a154-c95bb6cfd407"
   },
   "outputs": [],
   "source": [
    "# almaceno los resultados de la Bayesian Optimization\n",
    "# y capturo los mejores hiperparametros encontrados\n",
    "\n",
    "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
    "\n",
    "# ordeno en forma descendente por AUC = y\n",
    "setorder(tb_bayesiana, -y, -num_iterations)\n",
    "\n",
    "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
    "fwrite( tb_bayesiana,\n",
    "  file=\"BO_log.txt\",\n",
    "  sep=\"\\t\"\n",
    ")\n",
    "\n",
    "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
    "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
    "  1, # el primero es el de mejor AUC\n",
    "  list(num_leaves, min_data_in_leaf, num_iterations)\n",
    "]\n",
    "\n",
    "print(PARAM$out$lgbm$mejores_hiperparametros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb554cb-1d96-4f6b-ae1c-c9a076f8dbdc",
   "metadata": {
    "id": "ddb554cb-1d96-4f6b-ae1c-c9a076f8dbdc"
   },
   "source": [
    "### 7.3.3 Produccion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39492c3-756f-47a5-8747-93ade8275306",
   "metadata": {
    "id": "c39492c3-756f-47a5-8747-93ade8275306"
   },
   "source": [
    "### Final Training\n",
    "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xhKi_G_sYQqq",
   "metadata": {
    "id": "xhKi_G_sYQqq"
   },
   "source": [
    "#### Final Training Dataset\n",
    "\n",
    "Aqui esta la gran decision de en qué meses hago el Final Training\n",
    "<br> debo utilizar los mejores hiperparámetros que encontré en la optimización bayesiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qyHfS_X0zd7o",
   "metadata": {
    "id": "qyHfS_X0zd7o"
   },
   "outputs": [],
   "source": [
    "PARAM$trainingstrategy$final_train <- c( 202107,\n",
    "  202106, 202105, 202104, 202103, 202102, 202101,\n",
    "  202012, 202011, 202010, 202009, 202008, 202007,\n",
    "  202006, 202005\n",
    ")\n",
    "\n",
    "dataset[, fold_final_train := foto_mes %in% PARAM$trainingstrategy$final_train ]\n",
    "\n",
    "# creo el dfinal_train en formato  LightGBM\n",
    "dfinal_train <- lgb.Dataset(\n",
    "  data= data.matrix(dataset[fold_final_train == TRUE, campos_buenos, with= FALSE]),\n",
    "  label= dataset[fold_final_train == TRUE, clase01],\n",
    "  free_raw_data= TRUE\n",
    ")\n",
    "\n",
    "nrow( dfinal_train) # verifico el tamaño"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HATRyklxYUpT",
   "metadata": {
    "id": "HATRyklxYUpT"
   },
   "source": [
    "#### Final Training Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b9f33c-e0a0-4ea6-8169-4a6180cc5d01",
   "metadata": {
    "id": "d6b9f33c-e0a0-4ea6-8169-4a6180cc5d01"
   },
   "outputs": [],
   "source": [
    "# uno los parametros fijos y los mejores encontrados de los variables\n",
    "fijos <- copy(PARAM$lgbm$param_fijos)\n",
    "\n",
    "# quito lo que optimice en la Bayesian Optimization\n",
    "fijos$num_iterations <- NULL\n",
    "fijos$early_stopping_rounds <- NULL\n",
    "\n",
    "# agrego a los hiperparametros fijos los que encontre con la Bayesian Optimization\n",
    "param_final <- c(fijos, PARAM$out$lgbm$mejores_hiperparametros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d3494f-0401-4f3e-9b69-f488a737879d",
   "metadata": {
    "id": "05d3494f-0401-4f3e-9b69-f488a737879d"
   },
   "source": [
    "#### Training\n",
    "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa239848-1c28-4ee5-984a-073903b4b279",
   "metadata": {
    "id": "fa239848-1c28-4ee5-984a-073903b4b279"
   },
   "outputs": [],
   "source": [
    "final_model <- lgb.train(\n",
    "  data= dfinal_train,\n",
    "  param= param_final,\n",
    "  verbose= -100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RC1ju-5MZN5s",
   "metadata": {
    "id": "RC1ju-5MZN5s"
   },
   "outputs": [],
   "source": [
    "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
    "\n",
    "lgb.save(final_model, \"modelo.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VEpv4RYOZHTU",
   "metadata": {
    "id": "VEpv4RYOZHTU"
   },
   "outputs": [],
   "source": [
    "# ahora imprimo la importancia de variables\n",
    "\n",
    "tb_importancia <- as.data.table(lgb.importance(final_model))\n",
    "archivo_importancia <- \"impo.txt\"\n",
    "\n",
    "fwrite( tb_importancia,\n",
    "  file= archivo_importancia,\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea225b3-ce02-42e2-8330-b10ed250d172",
   "metadata": {
    "id": "7ea225b3-ce02-42e2-8330-b10ed250d172"
   },
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164981bb-f4c1-4228-8bc9-32e58a383c05",
   "metadata": {
    "id": "164981bb-f4c1-4228-8bc9-32e58a383c05"
   },
   "source": [
    "Aplico el modelo final a los datos del futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eJ7RbT271v-R",
   "metadata": {
    "id": "eJ7RbT271v-R"
   },
   "outputs": [],
   "source": [
    "PARAM$trainingstrategy$future <- c(202109)\n",
    "\n",
    "dfuture <- dataset[ foto_mes %in% PARAM$trainingstrategy$future ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ca61c8-fa24-4ce5-8be1-323aca018e8f",
   "metadata": {
    "id": "88ca61c8-fa24-4ce5-8be1-323aca018e8f"
   },
   "outputs": [],
   "source": [
    "# aplico final_model   a dfuture\n",
    "\n",
    "prediccion <- predict(\n",
    "  final_model,\n",
    "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79u0ZvjJZblE",
   "metadata": {
    "id": "79u0ZvjJZblE"
   },
   "source": [
    "#### Tabla Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TB6aerGDZeTo",
   "metadata": {
    "id": "TB6aerGDZeTo"
   },
   "outputs": [],
   "source": [
    "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
    "tb_prediccion[, prob := prediccion]\n",
    "\n",
    "# grabo las probabilidad del modelo\n",
    "#  me va a ser util para hacer Ensembles de modelos\n",
    "fwrite(tb_prediccion,\n",
    "  file= \"prediccion.txt\",\n",
    "  sep= \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8412d838-5bd5-454e-b3a9-5eaa18d80a50",
   "metadata": {
    "id": "8412d838-5bd5-454e-b3a9-5eaa18d80a50"
   },
   "source": [
    "Kaggle Competition Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55970cb6-856a-46e3-a893-7f36b8352b8e",
   "metadata": {
    "id": "55970cb6-856a-46e3-a893-7f36b8352b8e"
   },
   "source": [
    "Genero las salidas y hago los submits a Kaggle\n",
    "<br>El notebook esta preparado para la Modalidad Gerencial, los analistas deben hacer cambios.\n",
    "<br> Los analistas deben cambiar **competencia** a SU competencia  \"labo-i-2025-rosario-analista-jr\"   o  la original \"labo-i-2025-rosario\"  para los Senior\n",
    "<br> Los cortes  dependen de la cantidad de registros, multiplicar por 2 para los Analistas Jr y por 10 para los Analista Sr\n",
    "\n",
    "Los Analista Sr luego de meditar cuidadosamente reducirán la cantidad de cortes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fa2439-b0e9-49e0-a861-71d7315d6e1c",
   "metadata": {
    "id": "e5fa2439-b0e9-49e0-a861-71d7315d6e1c"
   },
   "outputs": [],
   "source": [
    "# genero archivos con los  \"envios\" mejores\n",
    "# suba TODOS los archivos a Kaggle\n",
    "\n",
    "PARAM$kaggle$competencia <- \"labo-i-2025-rosario-gerencial\"\n",
    "PARAM$kaggle$cortes <- seq(800, 1300, by = 50)\n",
    "\n",
    "# ordeno por probabilidad descendente\n",
    "setorder(tb_prediccion, -prob)\n",
    "\n",
    "dir.create(\"kaggle\")\n",
    "\n",
    "for (envios in PARAM$kaggle$cortes) {\n",
    "\n",
    "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
    "  tb_prediccion[1:envios, Predicted := 1L] # marclo los primeros\n",
    "\n",
    "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
    "\n",
    "  # grabo el archivo\n",
    "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
    "    file= archivo_kaggle,\n",
    "    sep= \",\"\n",
    "  )\n",
    "\n",
    "  # subida a Kaggle, armo la linea de comando\n",
    "  comando <- \"kaggle competitions submit\"\n",
    "  competencia <- paste(\"-c\", PARAM$kaggle$competencia)\n",
    "  arch <- paste( \"-f\", archivo_kaggle)\n",
    "\n",
    "  mensaje <- paste0(\"-m 'envios=\", envios,\n",
    "  \"  semilla=\", PARAM$semilla_primigenia,\n",
    "    \"'\" )\n",
    "\n",
    "  linea <- paste( comando, competencia, arch, mensaje)\n",
    "\n",
    "  salida <- system(linea, intern=TRUE) # el submit a Kaggle\n",
    "  cat(salida, \"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C94tK-xid6p2",
   "metadata": {
    "id": "C94tK-xid6p2"
   },
   "outputs": [],
   "source": [
    "# grabo los parametros\n",
    "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
    "require(\"yaml\")\n",
    "\n",
    "write_yaml( PARAM, file=\"PARAM.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b615a62-20cc-4e95-9af2-6b6db38d5efb",
   "metadata": {
    "id": "1b615a62-20cc-4e95-9af2-6b6db38d5efb"
   },
   "outputs": [],
   "source": [
    "format(Sys.time(), \"%a %b %d %X %Y\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

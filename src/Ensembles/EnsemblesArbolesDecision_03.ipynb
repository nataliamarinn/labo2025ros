{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Ensembles de Arboles de Decision"
      ],
      "metadata": {
        "id": "O94qX1svwzoC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4 GBDT LightGBM"
      ],
      "metadata": {
        "id": "HsJFTcBZw1bE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La técnica de Gradient Boosting fue creada por Jerome H. Friedman en 1999 - 2001\n",
        "<br>Se implementaron librerías ineficientes\n",
        "<br>En 2016 se crea XGBoost, en 2017 LightGBM\n",
        "\n",
        "El Gradient Boosting of Decision Trees es un ensemble de árboles de decisión, para un nuevo registro la predicción se hace sumando el score que cada arbol asigna a ese registro.\n",
        "\n",
        "En GBDT la construccion de los árboles es secuencial, ya que el arbol n-simo se genera para predecir el error del modelo conformado por los  n-1 arboles previos, aunque sea un arbol de clasificación lo que se predice es un numero real mediante un arbol de regresión.\n"
      ],
      "metadata": {
        "id": "nsgvDbemw9Tc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>Qué tipo de perturbaciones se realiza LightGBM\n",
        "\n",
        "*   Se perturba el dataset, seleccionando para cada arbol un subconjunto de las columnas.\n",
        "*   El algortimo de arbol de decisión no presenta perturbaciones"
      ],
      "metadata": {
        "id": "nF6XblBIYnY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada arbolito de LightGBM se entrena sobre un dataset perturbado, que en principio posee :\n",
        "* todos los registros del dataset original\n",
        "* solo un porcentaje *feature_fraction* de las columnas originales del dataset"
      ],
      "metadata": {
        "id": "j75A--Tsx2df"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.4.1  Seteo del ambiente en Google Colab"
      ],
      "metadata": {
        "id": "PX0qg_c0yqob"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGY7H9xza7Zr"
      },
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PupIBNba7Zr"
      },
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LpZCst5a7Zs"
      },
      "outputs": [],
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYC_F-wla7Zs"
      },
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWLelftXa7Zt"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/labo1\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/labo1\" /content/buckets/b1\n",
        "\n",
        "mkdir -p ~/.kaggle\n",
        "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "\n",
        "archivo_origen=\"https://storage.googleapis.com/open-courses/austral2025-af91/labo1r/dataset_pequeno.csv\"\n",
        "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
        "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
        "\n",
        "if ! test -f $archivo_destino_bucket; then\n",
        "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $archivo_destino; then\n",
        "  cp  $archivo_destino_bucket  $archivo_destino\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4.2  LightGBM, una corrida"
      ],
      "metadata": {
        "id": "oSKhZRToy2F7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSU5vi00CPRS"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje **R** Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq8dySimCPRT"
      },
      "source": [
        "limpio el ambiente de R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iE0U4_WCPRT"
      },
      "outputs": [],
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJDwdD0dCPRU"
      },
      "outputs": [],
      "source": [
        "# cargo las librerias que necesito\n",
        "require(\"data.table\")\n",
        "require(\"rpart\")\n",
        "\n",
        "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
        "require(\"rlist\")\n",
        "\n",
        "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
        "require(\"lightgbm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui debe cargar SU semilla primigenia"
      ],
      "metadata": {
        "id": "M8-Pyp6CCPRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM <- list()\n",
        "PARAM$experimento <- 5420\n",
        "PARAM$semilla_primigenia <- 102191\n",
        "\n",
        "# estos hiperparametros de LightGBM surgieron de una Bayesian Optimization\n",
        "PARAM$lgb$num_iterations <- 1000  # cantidad de arbolitos\n",
        "PARAM$lgb$learning_rate <- 0.027\n",
        "PARAM$lgb$feature_fraction <- 0.8\n",
        "PARAM$lgb$min_data_in_leaf <- 76\n",
        "PARAM$lgb$num_leaves <- 8\n",
        "PARAM$lgb$max_bin <- 31\n"
      ],
      "metadata": {
        "id": "peRH7ySLCPRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# carpeta de trabajo\n",
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento_folder <- paste0(\"KA\", PARAM$experimento)\n",
        "dir.create(experimento_folder, showWarnings=FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
      ],
      "metadata": {
        "id": "1gZD6ZMvCPRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lectura del dataset\n",
        "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\", stringsAsFactors = TRUE)"
      ],
      "metadata": {
        "id": "Xi0emX2ECPRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paso la clase a binaria que tome valores {0,1}  enteros\n",
        "# set trabaja con la clase  POS = { BAJA+1, BAJA+2 }\n",
        "# esta estrategia es MUY importante\n",
        "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\", \"BAJA+1\"), 1L, 0L)]"
      ],
      "metadata": {
        "id": "-3XuBeDy1Ugj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# los campos que se van a utilizar\n",
        "campos_buenos <- setdiff(colnames(dataset), c(\"clase_ternaria\", \"clase01\"))"
      ],
      "metadata": {
        "id": "h8Anoo4Sel8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# establezco donde entreno\n",
        "dataset[, train := 0L]\n",
        "dataset[foto_mes %in% c(202107), train := 1L]"
      ],
      "metadata": {
        "id": "RA3cSJ6KaGwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset[train == 1L, campos_buenos, with = FALSE]),\n",
        "  label= dataset[train == 1L, clase01]\n",
        ")"
      ],
      "metadata": {
        "id": "T6Zr06HB1kMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# genero el modelo\n",
        "# estos hiperparametros  salieron de una laaarga Optmizacion Bayesiana\n",
        "set.seed( PARAM$semilla_primigenia ) # Establezco la semilla aleatoria\n",
        "\n",
        "modelo <- lgb.train(\n",
        "  data= dtrain,\n",
        "  param= list(\n",
        "    objective= \"binary\",\n",
        "    max_bin= PARAM$lgb$max_bin,\n",
        "    learning_rate= PARAM$lgb$learning_rate,\n",
        "    num_iterations= PARAM$lgb$num_iterations,\n",
        "    num_leaves= PARAM$lgb$num_leaves,\n",
        "    min_data_in_leaf= PARAM$lgb$min_data_in_leaf,\n",
        "    feature_fraction= PARAM$lgb$feature_fraction,\n",
        "    seed= PARAM$semilla_primigenia\n",
        "  )\n",
        ")\n"
      ],
      "metadata": {
        "id": "TI9_5pii2zCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ahora imprimo la importancia de variables\n",
        "tb_importancia <- as.data.table(lgb.importance(modelo))\n",
        "archivo_importancia <- \"impo.txt\"\n",
        "\n",
        "fwrite(tb_importancia,\n",
        "  file = archivo_importancia,\n",
        "  sep = \"\\t\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "69QcMsSkg9d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
        "\n",
        "lgb.save(modelo, \"modelo.txt\" )"
      ],
      "metadata": {
        "id": "lauiNeQDg-XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aplico el modelo a los datos sin clase\n",
        "dfuture <- dataset[foto_mes == 202109]\n",
        "\n",
        "# aplico el modelo a los datos nuevos\n",
        "prediccion <- predict(\n",
        "  modelo,\n",
        "  data.matrix(dfuture[, campos_buenos, with = FALSE])\n",
        ")\n"
      ],
      "metadata": {
        "id": "VQhEcNmBhF7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tabla de prediccion\n",
        "\n",
        "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
        "tb_prediccion[, prob := prediccion ]\n",
        "\n",
        "# grabo las probabilidad del modelo\n",
        "fwrite(tb_prediccion,\n",
        "  file = \"prediccion.txt\",\n",
        "  sep = \"\\t\"\n",
        ")"
      ],
      "metadata": {
        "id": "Z5LYpStThlIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# subidas a Kaggle\n",
        "# ordeno por probabilidad descendente\n",
        "setorder(tb_prediccion, -prob)"
      ],
      "metadata": {
        "id": "vSopCODCh6kL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# genero archivos con los  \"envios\" mejores\n",
        "# suba TODOS los archivos a Kaggle\n",
        "\n",
        "cortes <- seq(9000, 13500, by = 500)\n",
        "\n",
        "for (envios in cortes) {\n",
        "\n",
        "  tb_prediccion[, Predicted := 0L]\n",
        "  tb_prediccion[1:envios, Predicted := 1L]\n",
        "\n",
        "  archivo_kaggle <- paste0(\"KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
        "\n",
        "  # grabo el archivo\n",
        "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "    file = archivo_kaggle,\n",
        "    sep = \",\"\n",
        "  )\n",
        "\n",
        "  # subida a Kaggle\n",
        "  comando <- \"kaggle competitions submit\"\n",
        "  competencia <- \"-c labo-i-2025-rosario\"\n",
        "  arch <- paste( \"-f\", archivo_kaggle)\n",
        "\n",
        "  mensaje <- paste0(\"-m 'num_iterations=\", PARAM$lgb$num_iterations,\n",
        "    \"  learning_rate=\", PARAM$lgb$learning_rate,\n",
        "    \"  feature_fraction=\", PARAM$lgb$feature_fraction,\n",
        "    \"  min_data_in_leaf=\", PARAM$lgb$min_data_in_leaf,\n",
        "    \"  num_leaves=\",PARAM$lgb$num_leaves,\n",
        "    \"  max_bin=\", PARAM$lgb$max_bin,\n",
        "  \"'\" )\n",
        "\n",
        "  linea <- paste( comando, competencia, arch, mensaje)\n",
        "  salida <- system(linea, intern=TRUE)\n",
        "  cat(salida)\n",
        "}"
      ],
      "metadata": {
        "id": "-qtXKj-uiCJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMr6Z1enOyd3"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4.3  LightGBM  optimizacion de hiperparámetros"
      ],
      "metadata": {
        "id": "lO4QwOEU-xPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La optimizacion de los hiperparámetros de LightGBM mediante el método de optimizacion bayesiana será su *caballito de batalla* durante la asignatura !"
      ],
      "metadata": {
        "id": "75FU3LjSF2uN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJBO5Dcb_B7s"
      },
      "source": [
        "limpio el ambiente de R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPKFI6yP_B7s"
      },
      "outputs": [],
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6X8U6XF_B7t"
      },
      "outputs": [],
      "source": [
        "# cargo las librerias que necesito\n",
        "require(\"data.table\")\n",
        "require(\"rpart\")\n",
        "require(\"parallel\")\n",
        "\n",
        "if( !require(\"primes\") ) install.packages(\"primes\")\n",
        "require(\"primes\")\n",
        "\n",
        "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
        "require(\"rlist\")\n",
        "\n",
        "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
        "require(\"lightgbm\")\n",
        "\n",
        "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
        "require(\"DiceKriging\")\n",
        "\n",
        "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
        "require(\"mlrMBO\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui debe cargar SU semilla primigenia"
      ],
      "metadata": {
        "id": "_qZHeAHdCJQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM <- list()\n",
        "PARAM$experimento <- 5430\n",
        "PARAM$semilla_primigenia <- 102191\n",
        "\n",
        "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
        "# undersampling de 1.0  implica tomar TODOS los datos\n",
        "PARAM$trainingstrategy$undersampling <- 1.0\n",
        "\n",
        "PARAM$hyperparametertuning$iteraciones <- 100\n",
        "PARAM$hyperparametertuning$xval_folds <- 5\n",
        "PARAM$hyperparametertuning$POS_ganancia <- 117000\n",
        "PARAM$hyperparametertuning$NEG_ganancia <- -3000\n",
        "\n",
        "# Aqui se cargan los bordes de los hiperparametros\n",
        "PARAM$hs <- makeParamSet(\n",
        "  makeNumericParam(\"learning_rate\", lower = 0.01, upper = 0.3),\n",
        "  makeIntegerParam(\"num_leaves\", lower = 8L, upper = 1024L),\n",
        "  makeNumericParam(\"feature_fraction\", lower = 0.1, upper = 1.0),\n",
        "  makeIntegerParam(\"min_data_in_leaf\", lower = 1L, upper = 8000L),\n",
        "  makeIntegerParam(\"envios\", lower = 5000L, upper = 15000L)\n",
        ")"
      ],
      "metadata": {
        "id": "2y3Ai8F6CJQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# graba a un archivo los componentes de lista\n",
        "# para el primer registro, escribe antes los titulos\n",
        "\n",
        "loguear <- function(\n",
        "    reg, arch = NA, folder = \"./work/\",\n",
        "    ext = \".txt\", verbose = TRUE) {\n",
        "\n",
        "  archivo <- arch\n",
        "  if (is.na(arch)) archivo <- paste0(folder, substitute(reg), ext)\n",
        "\n",
        "  if (!file.exists(archivo)) # Escribo los titulos\n",
        "    {\n",
        "      linea <- paste0(\n",
        "        \"fecha\\t\",\n",
        "        paste(list.names(reg), collapse = \"\\t\"), \"\\n\"\n",
        "      )\n",
        "\n",
        "      cat(linea, file = archivo)\n",
        "    }\n",
        "\n",
        "  linea <- paste0(\n",
        "    format(Sys.time(), \"%Y%m%d %H%M%S\"), \"\\t\", # la fecha y hora\n",
        "    gsub(\", \", \"\\t\", toString(reg)), \"\\n\"\n",
        "  )\n",
        "\n",
        "  cat(linea, file = archivo, append = TRUE) # grabo al archivo\n",
        "\n",
        "  if (verbose) cat(linea) # imprimo por pantalla\n",
        "}\n"
      ],
      "metadata": {
        "id": "P8YNRVVbCvQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# esta funcion calcula internamente la ganancia de la prediccion probs\n",
        "# es llamada por lightgbm luego de construir cada  arbolito\n",
        "\n",
        "fganancia_logistic_lightgbm <- function(probs, datos) {\n",
        "  vpesos <- get_field(datos, \"weight\")\n",
        "\n",
        "  # vector de ganancias\n",
        "  vgan <- ifelse(vpesos == 1.0000002, PARAM$hyperparametertuning$POS_ganancia,\n",
        "    ifelse(vpesos == 1.0000001, PARAM$hyperparametertuning$NEG_ganancia,\n",
        "      PARAM$hyperparametertuning$NEG_ganancia /\n",
        "        PARAM$trainingstrategy$undersampling\n",
        "    )\n",
        "  )\n",
        "\n",
        "  tbl <- as.data.table(list(\"vprobs\" = probs, \"vgan\" = vgan))\n",
        "  setorder(tbl, -vprobs)\n",
        "  ganancia <- tbl[1:GLOBAL_envios, sum(vgan)]\n",
        "\n",
        "  return(list(\n",
        "    \"name\" = \"ganancia\",\n",
        "    \"value\" = ganancia,\n",
        "    \"higher_better\" = TRUE\n",
        "  ))\n",
        "}\n"
      ],
      "metadata": {
        "id": "NnPKiCHuCwVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# esta funcion solo puede recibir los parametros que se estan optimizando\n",
        "# el resto de los parametros se pasan como variables globales,\n",
        "# la semilla del mal ...\n",
        "\n",
        "\n",
        "EstimarGanancia_lightgbm <- function(x) {\n",
        "  gc() # libero memoria\n",
        "\n",
        "  # llevo el registro de la iteracion por la que voy\n",
        "  GLOBAL_iteracion <<- GLOBAL_iteracion + 1\n",
        "\n",
        "  # para usar en fganancia_logistic_lightgbm\n",
        "  # asigno la variable global\n",
        "  GLOBAL_envios <<- as.integer(x$envios / PARAM$hyperparametertuning$xval_folds)\n",
        "\n",
        "  # cantidad de folds para cross validation\n",
        "  kfolds <- PARAM$hyperparametertuning$xval_folds\n",
        "\n",
        "  param_basicos <- list(\n",
        "    objective= \"binary\",\n",
        "    metric= \"custom\",\n",
        "    first_metric_only= TRUE,\n",
        "    boost_from_average= TRUE,\n",
        "    feature_pre_filter= FALSE,\n",
        "    verbosity= -100,\n",
        "    max_bin= 31, # por ahora, lo dejo fijo\n",
        "    num_iterations= 9999, # valor grande, lo limita early_stopping_rounds\n",
        "    force_row_wise= TRUE, # para evitar warning\n",
        "    seed= ksemilla_azar1\n",
        "  )\n",
        "\n",
        "  # el parametro discolo, que depende de otro\n",
        "  param_variable <- list(\n",
        "    early_stopping_rounds =\n",
        "      as.integer(50 + 5 / x$learning_rate)\n",
        "  )\n",
        "\n",
        "  param_completo <- c(param_basicos, param_variable, x)\n",
        "\n",
        "  set.seed(ksemilla_azar1)\n",
        "  modelocv <- lgb.cv(\n",
        "    data= dtrain,\n",
        "    eval= fganancia_logistic_lightgbm,\n",
        "    stratified= TRUE, # sobre el cross validation\n",
        "    nfold= kfolds, # folds del cross validation\n",
        "    param= param_completo,\n",
        "    verbose= -100\n",
        "  )\n",
        "\n",
        "  # obtengo la ganancia\n",
        "  ganancia <- unlist(modelocv$record_evals$valid$ganancia$eval)[modelocv$best_iter]\n",
        "\n",
        "  ganancia_normalizada <- ganancia * kfolds # normailizo la ganancia\n",
        "\n",
        "  # asigno el mejor num_iterations\n",
        "  param_completo$num_iterations <- modelocv$best_iter\n",
        "  # elimino de la lista el componente\n",
        "  param_completo[\"early_stopping_rounds\"] <- NULL\n",
        "\n",
        "\n",
        "  # el lenguaje R permite asignarle ATRIBUTOS a cualquier variable\n",
        "  # esta es la forma de devolver un parametro extra\n",
        "  attr(ganancia_normalizada, \"extras\") <-\n",
        "    list(\"num_iterations\" = modelocv$best_iter)\n",
        "\n",
        "  # logueo\n",
        "  xx <- param_completo\n",
        "  xx$ganancia <- ganancia_normalizada # le agrego la ganancia\n",
        "  xx$iteracion <- GLOBAL_iteracion\n",
        "  loguear(xx, arch = klog)\n",
        "\n",
        "  # Voy registrando la importancia de variables\n",
        "  if (ganancia_normalizada > GLOBAL_gananciamax) {\n",
        "    GLOBAL_gananciamax <<- ganancia_normalizada\n",
        "    modelo <- lgb.train(\n",
        "      data = dtrain,\n",
        "      param = param_completo,\n",
        "      verbose = -100\n",
        "    )\n",
        "\n",
        "    tb_importancia <- as.data.table(lgb.importance(modelo))\n",
        "    archivo_importancia <- paste0(\"impo_\", GLOBAL_iteracion, \".txt\")\n",
        "    fwrite(tb_importancia,\n",
        "      file = archivo_importancia,\n",
        "      sep = \"\\t\" )\n",
        "\n",
        "    loguear(xx, arch = klog_mejor)\n",
        "  }\n",
        "\n",
        "  return(ganancia_normalizada)\n",
        "}\n"
      ],
      "metadata": {
        "id": "kZSD7pUUCy58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "aqui se inicia el programa"
      ],
      "metadata": {
        "id": "P7Pw1KLeE3UH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# carpeta de trabajo\n",
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento_folder <- paste0(\"HT\", PARAM$experimento)\n",
        "dir.create(experimento_folder, showWarnings=FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
      ],
      "metadata": {
        "id": "w1lb19whCJQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# genero numeros primos\n",
        "primos <- generate_primes(min = 100000, max = 1000000)\n",
        "set.seed(PARAM$semilla_primigenia) # inicializo\n",
        "# me quedo con PARAM$qsemillas   semillas\n",
        "PARAM$semillas <- sample(primos, 2 )\n",
        "ksemilla_azar1 <- PARAM$semillas[1]\n",
        "ksemilla_azar2 <- PARAM$semillas[2]\n"
      ],
      "metadata": {
        "id": "fbLF3Vr0DAeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# en estos archivos quedan los resultados\n",
        "\n",
        "kbayesiana <- paste0(PARAM$experimento, \".RDATA\")\n",
        "klog <- paste0(PARAM$experimento, \".txt\")\n",
        "klog_mejor <- paste0(PARAM$experimento, \"_mejor.txt\")\n",
        "\n",
        "GLOBAL_iteracion <- 0 # inicializo la variable global\n",
        "GLOBAL_gananciamax <- -1 # inicializo la variable global\n",
        "\n",
        "# si ya existe el archivo log, traigo hasta donde llegue\n",
        "if (file.exists(klog)) {\n",
        "  tabla_log <- fread(klog)\n",
        "  GLOBAL_iteracion <- nrow(tabla_log)\n",
        "  GLOBAL_gananciamax <- tabla_log[, max(ganancia)]\n",
        "}\n"
      ],
      "metadata": {
        "id": "QvOokHUvuolF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lectura del dataset\n",
        "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")"
      ],
      "metadata": {
        "id": "xcOJpoFvCJQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset <- dataset[foto_mes %in% c(202107)]"
      ],
      "metadata": {
        "id": "JorOk_A8EhSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paso la clase a binaria que tome valores {0,1}  enteros\n",
        "dataset[\n",
        "  foto_mes %in% c(202107),\n",
        "  clase01 := ifelse(clase_ternaria == \"CONTINUA\", 0L, 1L)\n",
        "]"
      ],
      "metadata": {
        "id": "JDg9xZVYrwvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# los campos que se van a utilizar\n",
        "campos_buenos <- setdiff(\n",
        "  colnames(dataset),\n",
        "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "E68xpDYAr0nK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defino los datos que forma parte del training\n",
        "# aqui se hace el undersampling de los CONTINUA\n",
        "# notar que para esto utilizo la SEGUNDA semilla\n",
        "\n",
        "set.seed(ksemilla_azar2)\n",
        "dataset[, azar := runif(nrow(dataset))]\n",
        "dataset[, training := 0L]\n",
        "dataset[\n",
        "  foto_mes %in% c(202107) &\n",
        "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
        "  training := 1L\n",
        "]"
      ],
      "metadata": {
        "id": "G8zeYUfSr3GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "dtrain <- lgb.Dataset(\n",
        "  data = data.matrix(dataset[training == 1L, campos_buenos, with = FALSE]),\n",
        "  label = dataset[training == 1L, clase01],\n",
        "  weight = dataset[training == 1L, ifelse(clase_ternaria == \"BAJA+2\", 1.0000002, ifelse(clase_ternaria == \"BAJA+1\", 1.0000001, 1.0))],\n",
        "  free_raw_data = FALSE\n",
        ")\n"
      ],
      "metadata": {
        "id": "se8_aKuMr5CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui comienza la configuracion de la Bayesian Optimization\n",
        "funcion_optimizar <- EstimarGanancia_lightgbm # la funcion que voy a maximizar\n",
        "\n",
        "configureMlr(show.learner.output = FALSE)\n",
        "\n",
        "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
        "# por favor, no desesperarse por lo complejo\n",
        "obj.fun <- makeSingleObjectiveFunction(\n",
        "  fn = funcion_optimizar, # la funcion que voy a maximizar\n",
        "  minimize = FALSE, # estoy Maximizando la ganancia\n",
        "  noisy = TRUE,\n",
        "  par.set = PARAM$hs, # definido al comienzo del programa\n",
        "  has.simple.signature = FALSE # paso los parametros en una lista\n",
        ")\n",
        "\n",
        "# cada 600 segundos guardo el resultado intermedio\n",
        "ctrl <- makeMBOControl(\n",
        "  save.on.disk.at.time = 600, # se graba cada 600 segundos\n",
        "  save.file.path = kbayesiana\n",
        ") # se graba cada 600 segundos\n",
        "\n",
        "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
        "ctrl <- setMBOControlTermination(\n",
        "  ctrl,\n",
        "  iters = PARAM$hyperparametertuning$iteraciones\n",
        ") # cantidad de iteraciones\n",
        "\n",
        "# defino el método estandar para la creacion de los puntos iniciales,\n",
        "# los \"No Inteligentes\"\n",
        "ctrl <- setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())\n",
        "\n",
        "# establezco la funcion que busca el maximo\n",
        "surr.km <- makeLearner(\n",
        "  \"regr.km\",\n",
        "  predict.type = \"se\",\n",
        "  covtype = \"matern3_2\",\n",
        "  control = list(trace = TRUE)\n",
        ")\n"
      ],
      "metadata": {
        "id": "CsRYGGeN-1ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inicio la optimizacion bayesiana\n",
        "\n",
        "if (!file.exists(kbayesiana)) {\n",
        "  run <- mbo(obj.fun, learner = surr.km, control = ctrl)\n",
        "} else {\n",
        "  run <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
        "}"
      ],
      "metadata": {
        "id": "TissqCCHD1uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vu-1vf5LrVg"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}